{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnil\u001b[39;00m \u001b[38;5;66;03m# https://nilearn.github.io/stable/quickstart.html\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plotting\n",
      "File \u001b[0;32m/scratch/users/neuroimage/conda/venv/lib/python3.11/site-packages/nilearn/__init__.py:68\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info\u001b[39m.\u001b[39mmajor \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info\u001b[39m.\u001b[39mminor \u001b[39m==\u001b[39m \u001b[39m7\u001b[39m:\n\u001b[1;32m     65\u001b[0m         _py37_deprecation_warning()\n\u001b[0;32m---> 68\u001b[0m _check_module_dependencies()\n\u001b[1;32m     69\u001b[0m _python_deprecation_warnings()\n\u001b[1;32m     72\u001b[0m \u001b[39m# Monkey-patch gzip to have faster reads on large gzip files\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/users/neuroimage/conda/venv/lib/python3.11/site-packages/nilearn/version.py:179\u001b[0m, in \u001b[0;36m_check_module_dependencies\u001b[0;34m(is_nilearn_installing)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mfor\u001b[39;00m (module_name, module_metadata) \u001b[39min\u001b[39;00m REQUIRED_MODULE_METADATA:\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_nilearn_installing \u001b[39mand\u001b[39;00m\n\u001b[1;32m    176\u001b[0m             \u001b[39mnot\u001b[39;00m module_metadata[\u001b[39m'\u001b[39m\u001b[39mrequired_at_installation\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    177\u001b[0m         \u001b[39m# Skip check only when installing and it's a module that\u001b[39;00m\n\u001b[1;32m    178\u001b[0m         \u001b[39m# will be auto-installed.\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m         _import_module_with_version_check(\n\u001b[1;32m    180\u001b[0m             module_name\u001b[39m=\u001b[39;49mmodule_name,\n\u001b[1;32m    181\u001b[0m             minimum_version\u001b[39m=\u001b[39;49mmodule_metadata[\u001b[39m'\u001b[39;49m\u001b[39mmin_version\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    182\u001b[0m             install_info\u001b[39m=\u001b[39;49mmodule_metadata\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39minstall_info\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m/scratch/users/neuroimage/conda/venv/lib/python3.11/site-packages/nilearn/version.py:71\u001b[0m, in \u001b[0;36m_import_module_with_version_check\u001b[0;34m(module_name, minimum_version, install_info)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check that module is installed with a recent enough version.\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39m__import__\u001b[39;49m(module_name)\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     73\u001b[0m     user_friendly_info \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mModule \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m could not be found. \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     74\u001b[0m         module_name,\n\u001b[1;32m     75\u001b[0m         install_info \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mPlease install it properly to use nilearn.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/scratch/users/neuroimage/conda/venv/lib/python3.11/site-packages/pandas/__init__.py:138\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    121\u001b[0m     concat,\n\u001b[1;32m    122\u001b[0m     lreshape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     qcut,\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[0;32m--> 138\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m testing\n\u001b[1;32m    139\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_print_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[1;32m    141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    142\u001b[0m     \u001b[39m# excel\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     ExcelFile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     read_spss,\n\u001b[1;32m    172\u001b[0m )\n",
      "File \u001b[0;32m/scratch/users/neuroimage/conda/venv/lib/python3.11/site-packages/pandas/testing.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mPublic testing utility functions.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_testing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     assert_extension_array_equal,\n\u001b[1;32m      8\u001b[0m     assert_frame_equal,\n\u001b[1;32m      9\u001b[0m     assert_index_equal,\n\u001b[1;32m     10\u001b[0m     assert_series_equal,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_extension_array_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_frame_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_series_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_index_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m ]\n",
      "File \u001b[0;32m/scratch/users/neuroimage/conda/venv/lib/python3.11/site-packages/pandas/_testing/__init__.py:914\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpytest\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     \u001b[39mreturn\u001b[39;00m pytest\u001b[39m.\u001b[39mraises(expected_exception, match\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 914\u001b[0m cython_table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39mcommon\u001b[39m.\u001b[39m_cython_table\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    917\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[1;32m    918\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[39m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[39m    keys and expected result.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import gc\n",
    "import os\n",
    "# import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from io import BytesIO\n",
    "# import matplotlib.pyplot as plt\n",
    "import nilearn as nil # https://nilearn.github.io/stable/quickstart.html\n",
    "import time\n",
    "from nilearn import plotting\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "import io\n",
    "import ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/scratch/users/neuroimage/conda/data/preprocessed/imgss'\n",
    "meta_data_path = '/scratch/users/neuroimage/conda/data/ADNI1_Complete_2Yr_3T_4_18_2023.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I205567</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>66</td>\n",
       "      <td>m18</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; ; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/29/2008</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>4/12/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I66824</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>65</td>\n",
       "      <td>bl</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; ; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/21/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>4/12/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I79080</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>65</td>\n",
       "      <td>m06</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; ; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/11/2007</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>4/12/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I143856</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>67</td>\n",
       "      <td>m24</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; ; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/23/2009</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>4/12/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I99265</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "      <td>F</td>\n",
       "      <td>66</td>\n",
       "      <td>m12</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; ; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/06/2008</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>4/12/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image Data ID     Subject Group Sex  Age Visit Modality        Description   \n",
       "0       I205567  136_S_1227   MCI   F   66   m18      MRI  MPR; ; N3; Scaled  \\\n",
       "1        I66824  136_S_1227   MCI   F   65    bl      MRI  MPR; ; N3; Scaled   \n",
       "2        I79080  136_S_1227   MCI   F   65   m06      MRI  MPR; ; N3; Scaled   \n",
       "3       I143856  136_S_1227   MCI   F   67   m24      MRI  MPR; ; N3; Scaled   \n",
       "4        I99265  136_S_1227   MCI   F   66   m12      MRI  MPR; ; N3; Scaled   \n",
       "\n",
       "        Type   Acq Date Format Downloaded  \n",
       "0  Processed  9/29/2008  NiFTI  4/12/2023  \n",
       "1  Processed  2/21/2007  NiFTI  4/12/2023  \n",
       "2  Processed  9/11/2007  NiFTI  4/12/2023  \n",
       "3  Processed  3/23/2009  NiFTI  4/12/2023  \n",
       "4  Processed  3/06/2008  NiFTI  4/12/2023  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(meta_data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(I205567, 136_S_1227)</th>\n",
       "      <td>I205567</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(I66824, 136_S_1227)</th>\n",
       "      <td>I66824</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(I79080, 136_S_1227)</th>\n",
       "      <td>I79080</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(I143856, 136_S_1227)</th>\n",
       "      <td>I143856</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(I99265, 136_S_1227)</th>\n",
       "      <td>I99265</td>\n",
       "      <td>136_S_1227</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Image Data ID     Subject Group\n",
       "(I205567, 136_S_1227)       I205567  136_S_1227   MCI\n",
       "(I66824, 136_S_1227)         I66824  136_S_1227   MCI\n",
       "(I79080, 136_S_1227)         I79080  136_S_1227   MCI\n",
       "(I143856, 136_S_1227)       I143856  136_S_1227   MCI\n",
       "(I99265, 136_S_1227)         I99265  136_S_1227   MCI"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df[['Image Data ID', 'Subject', 'Group']].set_index(df[['Image Data ID', 'Subject', 'Group']].apply(lambda x: (x['Image Data ID'], x['Subject']), axis=1))\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = df_new['Group'].to_dict()\n",
    "# df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/users/neuroimage/conda/data/preprocessed/imgss/pp-023_S_1126-I94863-gm.nii.gz\n",
      "\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (121, 145, 121)\n",
      "affine:\n",
      "[[  0.    0.   -1.5  -0. ]\n",
      " [  0.   -1.5   0.   -0. ]\n",
      " [ -1.5   0.    0.  180. ]\n",
      " [  0.    0.    0.    1. ]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 121 145 121   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.  1.5 1.5 1.5 0.  0.  0.  0. ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.70710677\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : -0.70710677\n",
      "qoffset_x       : -0.0\n",
      "qoffset_y       : -0.0\n",
      "qoffset_z       : 180.0\n",
      "srow_x          : [ 0.   0.  -1.5 -0. ]\n",
      "srow_y          : [ 0.  -1.5  0.  -0. ]\n",
      "srow_z          : [ -1.5   0.    0.  180. ]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pair the image with labels and put them into respective folder\n",
    "out_dir = '/scratch/users/neuroimage/conda/data/prepared_data/'\n",
    "for filename in os.listdir(data_path):\n",
    "    file_path = os.path.join(data_path, filename)\n",
    "    if os.path.isfile(file_path) and filename.endswith('gm.nii.gz'):\n",
    "        split_str = filename.split('-')\n",
    "        # print(split_str)\n",
    "        img_id = split_str[2]\n",
    "        subject = split_str[1]\n",
    "        assert (img_id, subject) in df_dict\n",
    "        class_name = df_dict[(img_id, subject)]\n",
    "        # print(type(category))\n",
    "        print(os.path.join(data_path, filename))\n",
    "        img = nib.load(os.path.join(data_path, filename))\n",
    "        print(img)\n",
    "        \n",
    "        data = img.get_fdata()\n",
    "        print(data.shape)\n",
    "        print(filename)\n",
    "        plt.imshow(data[-1,:,:], cmap='gray')\n",
    "        z_shape = data.shape[2]\n",
    "        for i in range(z_shape):\n",
    "            np_array = data[:,:,i]\n",
    "            img = Image.fromarray(np.uint8(np_array))\n",
    "            filename_new = filename.split('.')[0] + f'_{str(i)}.jpg'\n",
    "            # print(filename_new)\n",
    "            # print(os.path.join(out_dir, class_name, filename_new)) \n",
    "            img.save(os.path.join(out_dir, class_name, filename_new))\n",
    "        print('finish', filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "filename = 'pp-051_S_1331-I82509-gm.nii.gz'\n",
    "img = nib.load(os.path.join(data_path, filename))\n",
    "\n",
    "data = img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "batch_size = 32\n",
    "\n",
    "data_transform = {\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "full_dataset = datasets.ImageFolder(out_dir, transform=data_transform)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f463ec5d490>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/neuroimage/conda/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning:\n",
      "\n",
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\n",
      "/scratch/users/neuroimage/conda/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning:\n",
      "\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet50(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m num_ftrs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features\n\u001b[0;32m---> 11\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m))\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# dataloader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# resnet\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(train_dataset.classes))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_corrects = 0\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_acc = train_corrects.double() / len(train_dataset)\n",
    "    test_loss = test_loss / len(test_dataset)\n",
    "    test_acc = test_corrects.double() / len(test_dataset)\n",
    "    print('Epoch [{}/{}], train_loss: {:.4f}, train_acc: {:.4f}, test_loss: {:.4f}, test_acc: {:.4f}'.format(\n",
    "        epoch+1, num_epochs, train_loss, train_acc, test_loss, test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ac8cfbc2efd46450d43056ef9f8bf8282b00a7a72fee075afebfd0ecbb1cd2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
