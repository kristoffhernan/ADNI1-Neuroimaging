{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjhISZUN8aq2",
    "outputId": "5be9830a-a3ca-4485-e174-b865d2655c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting antspyx\n",
      "  Downloading antspyx-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.4/326.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from antspyx) (0.13.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from antspyx) (1.2.1)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (from antspyx) (3.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from antspyx) (3.5.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from antspyx) (1.22.4)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from antspyx) (0.19.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from antspyx) (1.10.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from antspyx) (1.3.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from antspyx) (6.0)\n",
      "Collecting chart-studio\n",
      "  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from antspyx) (8.4.0)\n",
      "Collecting webcolors\n",
      "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from chart-studio->antspyx) (2.25.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from chart-studio->antspyx) (5.5.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from chart-studio->antspyx) (1.15.0)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->antspyx) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->antspyx) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->antspyx) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->antspyx) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->antspyx) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->antspyx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->antspyx) (2022.7.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->antspyx) (1.4.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->antspyx) (2023.2.27)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->antspyx) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image->antspyx) (3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->antspyx) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->antspyx) (1.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels->antspyx) (0.5.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->chart-studio->antspyx) (8.2.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->chart-studio->antspyx) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->chart-studio->antspyx) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->chart-studio->antspyx) (1.26.14)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->chart-studio->antspyx) (4.0.0)\n",
      "Installing collected packages: webcolors, retrying, chart-studio, antspyx\n",
      "Successfully installed antspyx-0.3.7 chart-studio-1.1.0 retrying-1.3.4 webcolors-1.12\n"
     ]
    }
   ],
   "source": [
    "# ANTSPYPX documentation https://antspyx.readthedocs.io/en/latest/core.html\n",
    "!pip install antspyx\n",
    "\n",
    "# not needed anymore\n",
    "# %env SM_FRAMEWORK=tf.keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBIK2yjA8kJJ",
    "outputId": "46bda9a7-b9cf-41e5-da62-8aefee4d27e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import ants\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f41YfVUAAQY0"
   },
   "outputs": [],
   "source": [
    "proj_path = r'/content/drive/MyDrive/Capstone-Project/'\n",
    "os.chdir(proj_path)\n",
    "\n",
    "base_data_path = os.path.join(proj_path, 'data')\n",
    "nfbs_path = os.path.join(base_data_path, 'nfbs-data')\n",
    "nfbs_zip = 'NFBS_Dataset.tar.gz'\n",
    "\n",
    "full_path = os.path.join(nfbs_path, 'NFBS_Dataset.tar.gz')\n",
    "\n",
    "# unzip files \n",
    "# import tarfile\n",
    "# file = tarfile.open(full_path)\n",
    "# file.extractall(base_path)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gecgNQrBtnR",
    "outputId": "e9356937-d203-479d-99e8-cdeb1fdd01b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each folder contains..\n",
      "['sub-A00028185_ses-NFB3_T1w_brainmask.nii.gz', 'sub-A00028185_ses-NFB3_T1w_brain.nii.gz', 'sub-A00028185_ses-NFB3_T1w.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print('Each folder contains..')\n",
    "print(os.listdir(os.path.join(nfbs_path, 'NFBS_Dataset/A00028185')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfcw6jfBEoW7"
   },
   "source": [
    "Each folder contains 3 types of images in nifti format..\n",
    "\n",
    "T1weighted :This is the raw MRI image with a single channel. Image is 3D and can be imagined as multiple 2D images stacked together.\n",
    "\n",
    "T1w_brainmask: It is the image mask of the brain or can be called as the ground truth. It is obtained using Beast(Brain extraction based on non local segmentation) method and applying manual edits by domain experts to remove non brain tissue.\n",
    "\n",
    "T1w_brain:This can be thought of as part of brain stripped from above T1weighted image. This is similar to overlaying mask to actual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PSrGvOhEOwq",
    "outputId": "454ccd9e-0b51-4e4e-de75-7c32685988b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image= (256, 256, 192)\n"
     ]
    }
   ],
   "source": [
    "img=ants.image_read(os.path.join(nfbs_path,'NFBS_Dataset/A00028185/sub-A00028185_ses-NFB3_T1w.nii.gz'))\n",
    "print('Shape of image=',img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "fAt7_dcvEv7G",
    "outputId": "36cca882-6e73-48a4-db2c-3a33ae6afdeb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2eac9daa-07d0-4915-95b6-a5470039a9ad\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brain_mask</th>\n",
       "      <th>brain</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "      <td>/content/drive/MyDrive/Capstone-Project/data/n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2eac9daa-07d0-4915-95b6-a5470039a9ad')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2eac9daa-07d0-4915-95b6-a5470039a9ad button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2eac9daa-07d0-4915-95b6-a5470039a9ad');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                          brain_mask  \\\n",
       "0  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "1  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "2  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "3  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "4  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "\n",
       "                                               brain  \\\n",
       "0  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "1  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "2  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "3  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "4  /content/drive/MyDrive/Capstone-Project/data/n...   \n",
       "\n",
       "                                                 raw  \n",
       "0  /content/drive/MyDrive/Capstone-Project/data/n...  \n",
       "1  /content/drive/MyDrive/Capstone-Project/data/n...  \n",
       "2  /content/drive/MyDrive/Capstone-Project/data/n...  \n",
       "3  /content/drive/MyDrive/Capstone-Project/data/n...  \n",
       "4  /content/drive/MyDrive/Capstone-Project/data/n...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#storing the address of 3 types of files\n",
    "brain_mask=[]\n",
    "brain=[]\n",
    "raw=[]\n",
    "for subdir, dirs, files in os.walk(os.path.join(nfbs_path,'NFBS_Dataset')):\n",
    "  for file in files:\n",
    "\n",
    "    #print os.path.join(subdir, file)y\n",
    "    filepath = subdir + os.sep + file\n",
    "\n",
    "    if filepath.endswith(\".gz\"):\n",
    "      if '_brainmask.' in filepath:\n",
    "        brain_mask.append(filepath)\n",
    "      elif '_brain.' in filepath:\n",
    "        brain.append(filepath)\n",
    "      else:\n",
    "        raw.append(filepath)\n",
    "\n",
    "#creating a dataframe for ease of use..\n",
    "data=pd.DataFrame({'brain_mask':brain_mask,'brain':brain,'raw':raw})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXL_hq_dILjY"
   },
   "outputs": [],
   "source": [
    "img = ants.image_read(data.raw.iloc[0])\n",
    "[ants.plot(img, crop=False, axis=ax) for ax in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQwJj7djLhXX"
   },
   "outputs": [],
   "source": [
    "#lets visualize a couple of examples\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(2):\n",
    "  fig,ax=plt.subplots(1,3,figsize=(10,7))\n",
    "  ax[0].set_title('Raw image')\n",
    "  img = nib.load(data.raw.iloc[i]).get_fdata()\n",
    "  ax[0].imshow(img[img.shape[0]//2])\n",
    "  ax[1].set_title('Skull strippedimage')\n",
    "  img = nib.load(data.brain.iloc[i]).get_fdata()\n",
    "  ax[1].imshow(img[img.shape[0]//2])\n",
    "  ax[2].set_title('Brain mask image')\n",
    "  img = nib.load(data.brain_mask.iloc[i]).get_fdata()\n",
    "  ax[2].imshow(img[img.shape[0]//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxMMXVJ-04Ju"
   },
   "source": [
    "We compute a histogram of the image intensity values. Its counting the number of pixels that falls into each bin. Because there are a set 256 bins, I can choose between the 125th and 175 bin to compute the mean.\n",
    "\n",
    "After computing the mean we can adjust the low and high thresholds above and below the mean to ensure that the mask includes only the brain tissue and not the empty space around it. This helps to exclude the regions of the image that have lower or higher intensity values than the brain tissue, which are likely to correspond to background noise or non-brain tissue regions.\n",
    "\n",
    "This masking is necessary for subsequent image processing steps, such as segmentation or registration, where we want to focus on the brain tissue and avoid any unwanted artifacts or background noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3f7sjJs6u4S"
   },
   "outputs": [],
   "source": [
    "# a = np.array([])\n",
    "# for idx, row in tqdm(data.iterrows()):\n",
    "#   img = ants.image_read(row['raw'])\n",
    "#   a = np.append(a, img)\n",
    "#   process = psutil.Process()\n",
    "#   memory_info = process.memory_info()\n",
    "#   # print(memory_info)\n",
    "#   if idx % 10 == 0:\n",
    "#     print(f\" After loading {idx + 1} images, Memory used: {memory_info.rss / 1024 / 1024:.2f} MB\")\n",
    "#   #print(f\"Finish reading {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAqA3JvXstBs"
   },
   "outputs": [],
   "source": [
    "# TAKES 1 HOUR TO RUN, DO NOT RUN AGAIN, WE HAVE DATAbIN PP_Images folder\n",
    "\n",
    "# want new img to have some similar indicator to previous img\n",
    "file_labels = [dirs for subdir, dirs, files in os.walk(os.path.join(nfbs_path, 'NFBS_Dataset'))]\n",
    "file_labels = file_labels[0]\n",
    "\n",
    "pp_img_dir = os.path.join(nfbs_path,'PP_Images', 'raw')\n",
    "pp_mask_dir = os.path.join(nfbs_path,'PP_Images', 'mask')\n",
    "\n",
    "# check if path exists, if not make it\n",
    "Path(pp_img_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(pp_mask_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "suffix = '_pp.nii.gz'\n",
    "\n",
    "# preprocessing loop\n",
    "for idx, row in tqdm(data.iterrows()):\n",
    "  img = ants.image_read(row['raw'])\n",
    "\n",
    "  # image histogram\n",
    "  hist, bins = np.histogram(img.numpy().ravel(), bins=256)\n",
    "\n",
    "  # mean intensity value of the brain tissue\n",
    "  mean_intensity = bins[125:175].mean()\n",
    "\n",
    "  # Set the lower and upper thresholds to exclude the empty space\n",
    "  low_threshold = mean_intensity + 0.1 * mean_intensity\n",
    "  high_threshold = np.amax(img.numpy()) - 0.1 * np.amax(img.numpy())\n",
    "\n",
    "  # binary mask of the brain region\n",
    "  mask = ants.get_mask(img, low_thresh=low_threshold, high_thresh=high_threshold, cleanup=2)\n",
    "\n",
    "  # n4 bias, normalize z score\n",
    "  img_n4 = ants.n4_bias_field_correction(img, shrink_factor=3, mask=mask, convergence={'iters':[20, 10, 10, 5], 'tol':1e-07}, rescale_intensities=True).iMath_normalize()\n",
    "\n",
    "  # resize\n",
    "  # interp_type= 1 (nearest neighbor)\n",
    "  img_mask_ds = ants.image_read(row['brain_mask']).resample_image((96,128,160), use_voxels=True, interp_type=1)\n",
    "  img_n4_ds = img_n4.resample_image((96,128,160), use_voxels=True, interp_type=1)\n",
    "\n",
    "  # saving\n",
    "  ants.image_write(img_n4_ds, os.path.join(pp_img_dir, file_labels[idx] + '_raw' + suffix), ri=False)\n",
    "  ants.image_write(img_mask_ds, os.path.join(pp_mask_dir, file_labels[idx] + '_mask' + suffix), ri=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnT-BG_7qAzk",
    "outputId": "07825f54-5899-4e57-ec64-b1dc4bd66573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " After loading 1 images, Memory used: 1108.59 MB\n",
      " After loading 11 images, Memory used: 1135.56 MB\n",
      " After loading 21 images, Memory used: 1210.33 MB\n",
      " After loading 31 images, Memory used: 1285.35 MB\n",
      " After loading 41 images, Memory used: 1360.38 MB\n",
      " After loading 51 images, Memory used: 1435.39 MB\n",
      " After loading 61 images, Memory used: 1510.46 MB\n",
      " After loading 71 images, Memory used: 1585.48 MB\n",
      " After loading 81 images, Memory used: 1660.50 MB\n",
      " After loading 91 images, Memory used: 1735.53 MB\n",
      " After loading 101 images, Memory used: 1810.62 MB\n",
      " After loading 111 images, Memory used: 1885.69 MB\n",
      " After loading 121 images, Memory used: 1960.58 MB\n",
      " After loading 1 images, Memory used: 1998.22 MB\n",
      " After loading 11 images, Memory used: 2072.99 MB\n",
      " After loading 21 images, Memory used: 2148.01 MB\n",
      " After loading 31 images, Memory used: 2223.04 MB\n",
      " After loading 41 images, Memory used: 2298.06 MB\n",
      " After loading 51 images, Memory used: 2373.08 MB\n",
      " After loading 61 images, Memory used: 2448.11 MB\n",
      " After loading 71 images, Memory used: 2523.13 MB\n",
      " After loading 81 images, Memory used: 2598.15 MB\n",
      " After loading 91 images, Memory used: 2673.18 MB\n",
      " After loading 101 images, Memory used: 2748.20 MB\n",
      " After loading 111 images, Memory used: 2823.22 MB\n",
      " After loading 121 images, Memory used: 2897.99 MB\n"
     ]
    }
   ],
   "source": [
    "# code very messy, fix later\n",
    "pp_path = os.path.join(nfbs_path, 'PP_Images')\n",
    "raw = []\n",
    "mask = []\n",
    "j = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(os.path.join(pp_path)):\n",
    "  j += 1\n",
    "  for i, file in enumerate(files):\n",
    "    if j == 2:\n",
    "      img = ants.image_read(os.path.join(pp_path, 'raw', file))\n",
    "      raw.append(img)\n",
    "    elif j == 3:\n",
    "      img = ants.image_read(os.path.join(pp_path, 'mask', file))\n",
    "      mask.append(img)\n",
    "    \n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    # print(memory_info)\n",
    "    if i % 10 == 0:\n",
    "      print(f\" After loading {i + 1} images, Memory used: {memory_info.rss / 1024 / 1024:.2f} MB\")\n",
    "    #print(f\"Finish reading {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iR02vgDhm5mT"
   },
   "source": [
    "Way less memory used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "PomoajOEeH0i",
    "outputId": "56e9599a-76da-419d-848d-186c71225efb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5e1dcabc2374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3D mask nice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mask' is not defined"
     ]
    }
   ],
   "source": [
    "# 3D mask nice\n",
    "ms = mask[0]\n",
    "[ants.plot(ms, crop=False, axis=ax) for ax in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9xv6o6bgiaL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage.io import imread\n",
    "from torch.utils import data as d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SegmentationDataSet(d.Dataset):\n",
    "  def __init__(self,\n",
    "               inputs: object,\n",
    "               targets: object,\n",
    "               transform=None\n",
    "               ):\n",
    "    self.inputs = inputs\n",
    "    self.targets = targets\n",
    "    self.transform = transform\n",
    "    self.inputs_dtype = torch.float32\n",
    "    self.targets_dtype = torch.long\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.inputs)\n",
    "\n",
    "  def __getitem__(self,\n",
    "                  index: int):\n",
    "    # select the sample\n",
    "    input_ID = self.inputs[index]\n",
    "    target_ID = self.targets[index]\n",
    "\n",
    "    # load input and target\n",
    "    x, y = ants.image_read(input_ID), ants.image_read(target_ID)\n",
    "    \n",
    "    # PREPROCESSING\n",
    "    if self.transform is not None:\n",
    "      \n",
    "      ######## Intensity correction \n",
    "      # image histogram\n",
    "      hist, bins = np.histogram(x.numpy().ravel(), bins=256)\n",
    "\n",
    "      # mean intensity value of the brain tissue\n",
    "      mean_intensity = bins[125:175].mean()\n",
    "\n",
    "      # Set the lower and upper thresholds to exclude the empty space\n",
    "      low_threshold = mean_intensity + 0.1 * mean_intensity\n",
    "      high_threshold = np.amax(x.numpy()) - 0.1 * np.amax(x.numpy())\n",
    "\n",
    "      # binary mask of the brain region\n",
    "      mask = ants.get_mask(x, low_thresh=low_threshold, high_thresh=high_threshold, cleanup=2)\n",
    "\n",
    "      # n4 bias\n",
    "      x = ants.n4_bias_field_correction(x, \n",
    "                                        shrink_factor=3, \n",
    "                                        mask=mask, \n",
    "                                        convergence={'iters':[20, 10, 10, 5],\n",
    "                                                     'tol':1e-07},\n",
    "                                        rescale_intensities=True)\n",
    "      ###########\n",
    "\n",
    "      # normalize intensities by z standard normal\n",
    "      x = x.iMath_normalize()\n",
    "\n",
    "      # resize\n",
    "      # interp_type= 1 (nearest neighbor)\n",
    "      y = y.resample_image((96,128,160), use_voxels=True, interp_type=1)\n",
    "      x = x.resample_image((96,128,160), use_voxels=True, interp_type=1)\n",
    "\n",
    "      # saving Fix later ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "      # ants.image_write(x, os.path.join(pp_img_dir, file_labels[idx] + '_raw' + suffix), ri=False)\n",
    "      # ants.image_write(y, os.path.join(pp_mask_dir, file_labels[idx] + '_mask' + suffix), ri=False)\n",
    "\n",
    "      # type casting\n",
    "    x = torch.from_numpy(x.numpy()).type(self.inputs_dtype)\n",
    "    y = torch.from_numpy(y.numpy()).type(self.inputs_dtype)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDR84CAjo0mz"
   },
   "outputs": [],
   "source": [
    "training_dataset = SegmentationDataSet(inputs=data['raw'][0:2],\n",
    "                    targets=data['brain_mask'][0:2],\n",
    "                    transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCxOiV2po2fV",
    "outputId": "51da7fbd-89c6-41ce-e695-cbde16fa5743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = shape: torch.Size([2, 96, 128, 160]); type: torch.float32\n",
      "x = min: 0.0; max: 1.0\n",
      "y = shape: torch.Size([2, 96, 128, 160]); class: tensor([0.0000, 0.0819, 0.3243, 0.3337, 1.0000]); type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "training_dataloader = d.DataLoader(dataset=training_dataset,\n",
    "             batch_size=2,\n",
    "             shuffle=True)\n",
    "\n",
    "# iter calls the __iter__() method on the dataloader\n",
    "# https://stackoverflow.com/a/62550190/16800940\n",
    "x, y = next(iter(training_dataloader))\n",
    "\n",
    "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
    "print(f'x = min: {x.min()}; max: {x.max()}')\n",
    "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
